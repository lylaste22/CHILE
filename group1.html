<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="">
    <meta name="author" content="">
    <!-- <link rel="shortcut icon" href="../../docs-assets/ico/favicon.png"> -->

    <title>CHILE 2015</title>

    <!-- Bootstrap core CSS -->
    <link href="//netdna.bootstrapcdn.com/bootswatch/3.0.2/yeti/bootstrap.min.css" rel="stylesheet">

    <!-- Custom styles for this template -->
    <link href="http://getbootstrap.com/examples/jumbotron-narrow/jumbotron-narrow.css" rel="stylesheet">

    <!-- Just for debugging purposes. Don't actually copy this line! -->
    <!--[if lt IE 9]><script src="../../docs-assets/js/ie8-responsive-file-warning.js"></script><![endif]-->

    <!-- HTML5 shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!--[if lt IE 9]>
      <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
      <script src="https://oss.maxcdn.com/libs/respond.js/1.3.0/respond.min.js"></script>
    <![endif]-->
    
        <script type="text/javascript" src="http://latex.codecogs.com/latexit.js"></script>
  </head>

  <body>

    <div class="container">
      <div class="header">
        <ul class="nav nav-pills pull-right">
          <li><a href="index.html">Home</a></li>
          <li class="active"><a href="group1.html">Group 1</a></li>
          <li><a href="group2.html">Group 2</a></li>
          <li><a href="group3.html">Group 3</a></li>
          <li><a href="https://github.com/lylaste22/CHILE" target="_blank">Code</a></li>
        </ul>
        <h3 class="text-muted">CHILE 2015</h3>
      </div>

      <div class="container">
        <h1 style="text-align:center">Chile-Harvard Innovative Learning Exchange 2015</h1>
      </div>
	<div class="jumbotron">
          <iframe src="//player.vimeo.com/video/85659466?color=ffffff" width="520" height="293" frameborder="0" webkitallowfullscreen mozallowfullscreen allowfullscreen></iframe>
      </div>


      <div class="row marketing">
        <div class="col-md-12">

        <h3> Source detection and source identification </h3>

	<p> Given the collection of images obtained from DECam, the first task is the detection of astronomical objects. Each image is taken by pointing the telescope at a specific part of the sky and the result is a pixelized 2D record of the brightness of that region. The pixel intensity in the image is due to the light coming from sources, background light, noise of the sensor or cosmic rays. Given the differences in intensity of each pixel of the image and the signature of groups of pixels, celestial objects can be identified and later classified as a star, a galaxy, an asteroid or a planet. The goal for this part of the project is to detect these sources as objects and characterize them taking into account the removal of cosmic rays. Characterization involves determining source brightness, source position on the sky and source shape as stars and distant galaxies appear as point sources. The data set contains images of the same part of the sky multiple times constituting multiple epoch records of the same object. </p>

	<p> Additionally, since the same part of the sky may have been already observed and recorded by various existing surveys, a cross-references with these known sources was completed to extract additional known information for each object identified.</p>
	
	<p> This part of the work-flow produces as output a catalog containing a list of all identified objects with all the extracted features.  </p>
	

	<h3> Data </h3>
	<ul>
		<li> Forty fields observed during four nights </li>
		<li> Every image covers 3 sq. deg. </li>
		<li> four times per nights (160 or 180 sec per exposure). </li>
		<li> g filter was used. </li>
		<li>61458 output files corresponding to 20486 processed images </li>
	</ul>
	
        <h3> Aim </h3>
        <p>Develop a pipeline in the cluster to process the 20K fitz images completing the following tasks:</p>
	<ol>
		<li> Collect all the available raw CCD images available in fitz format </li>
		<li> Obtain image meta data from the fitz header </li>
		<li> Remove cosmic rays using specific image read-noise and gain per CCD </li>
		<li> Identify astronomical objects in each image using parameters from meta-data extracted </li>
		<li> Generate a catalog with a list of all identified objects per image and additional information to be later used in the classification work </li>
		<li> Cross reference with Virtual Observatory to pull additional information for known objects </li>

	</ol>

	<h3> Procedure </h3>
	<h4> Cosmic ray rejection  </h2>

	<p>Cosmic rays are high energy charged particles, originating in outer space, that travel at nearly the speed of light and strike the Earth from all directions. Cosmic rays have a unique signature and should be removed from the catalog. Cosmic rays have hard edges, unlike stars or galaxies. This is because they are produced by individual particles that hit the detector and not by collections of photons that propagate through the atmosphere and the telescope optical system. </p> 
	
	<p>Conventional approaches to detect and eliminate cosmic rays from images rely on the difference in contrast between the cosmic ray and its surrounding environment. These types of algorithms may generate inaccurate results when the PSF Point Spread Function is smaller than the cosmic ray. A more reliable approach for discriminating between low resolution point sources and cosmic-rays was developed by Pieter van Dokkum based on a variation of Laplacian edge detection. This method is widely used for highlighting boundaries in digital images.  The algorithm identifies cosmic-rays of arbitrary shapes and sizes by the sharpness of their edges. The results are therefore, largely independent of the morphology of cosmic-rays. </p>
	
	<p>The python module Cosmics.py is used to detect and clean up cosmic ray hits on images based on Pieter van Dokkum's Laplacian algorithm. The module can handle images in FITS format. The process is iterative and typically requires 4 iterations for the optimal removal of cosmic rays from DECam observations. The module is robust and requires tuning on several user-defined parameters which are obtained from the image meta-data. The following non-default parameter values obtained from the FITS header work well with the collected DECam observations:</p>
	
	<pre><code>gain=4.5 (gain [electrons ADU−1 ] )
readn=7.0 (read noise [electrons] )
sigfrac=0.3 (fractional detection limit for neighboring pixels)
objlim=1 (contrast limit between cosmic rays and an underlying object) </code></pre>
	
	<p></p>
	<p>The image below shows an illustration of the original image including cosmic rays and their subsequent rejection using the cosmics.py module:</p>
	
	<center>
        	<img class="" src="images/pygif.gif" style="width:device-width;max-width:100%;margin:auto;display:inline"/>
        </center>
	
	<p></p>
	<p>Although the cosmics.py module accomplishes the cosmic ray defect removal very well for a single image, it does not work well for the 20K images available for processing due to time performance. CRBLASTER is an alternative implementation of the L.A.COSMIC algorithm written in the C language that employs an embarrassingly-parallel algorithm using the high-performance computing industry standard Message Passing Interface (MPI) library. As such, it is ideally suited to being implemented in a parallel-processing image-analysis application. </p>
	
	<p>The original package for CRBLASTER has hard-coded parameters including noise and gain. To obtain better results, we want to use specific parameter values obtained from the image meta-data. To achieve this, we patched the CRBLASTER application to accept parameters. The results for this customized version of the cosmic ray removal application obtained are equally effective as the python cosmics module as seen in the animation below:</p>
	
	<center>
        	<img class="" src="images/crgif.gif" style="width:device-width;max-width:100%;margin:auto;display:inline"/>
        </center>
	
	
	
	
	
  
	<h4> Photometry: Using SExtractor (SE) </h2>
	
	<p>SExtractor is a widely known software created by E. Bertin capable of detecting objects, extracting their flux (or magnitude) using a variety of different approaches and providing a rough classification of the identified objects using a star/non-star criteria (CLASS_STAR parameter; however, for faint objects, the confidence of classification is not very high).</p> 
		
	<p>In order to perform this task, SExtractor requires as input some paramaters given in every image as meta-data (CCD's gain, saturation, read noise, pixel scale and [stellar] FWHM), photometric zeropoint obtained (as a better calibration of the instrumental magnitude), in our particular case for DECam photometric calibration (http://soartelescope.org/noao/content/DECam-Photometric-Calibration) per CCD, and the filter that we are going to use for modeling a PSF according to the FWHM. </p>
	
	<p>The most important tasks in the workflow that SExtractor implements are the following:   </p>
	
	<ol>
		<li> <b>Background estimation:</b> </li>
		<p>SExtractor uses the parameter BACK_SIZE for estimating the background of the image as well as the RMS noise in that background. In our case, we use the default parameter given as 64 pixels because the average size of our objects in pixels is smaller than this value (in the worst case, it can be changed easily). The mean and the sigma of the background estimation are crucial for detection tasks.</p>
		
		<li><b>Additional Filtering:</b></li>
		Before the detection, we apply a filter for smoothing the image to increase the signal-to-noise ratio and therefore helping to detect fainter objects. The decision of using a filter was driven by the fact that our images are not extremely crowded. Typically, the recommendation for filtering is to use the SExtractor 'canonical' filters; gaussian, tophat, mexhat, block (especially the gaussian ones because they are adequate to a star's PSF) and choose the one which has a similar FWHM compared to the images. 
		</p>
		
		<p>The first approach used to create a pipeline was to implement the idea explained above using SExtractor's gaussian filters (commented code in testfits.py). In the final iteration of our implementation we 'create' our own gaussians filters according to the precise FWHM of the images using a Python implementation of a MATLAB's  fspecial function for creating gaussian filters, obtained from:</p>
<pre><code>import numpy as np

def matlab_style_gauss2D(shape=(3,3),sigma=0.5):
    """
    2D gaussian mask - should give the same result as MATLAB's
    fspecial('gaussian',[shape],[sigma])
    """
    m,n = [(ss-1.)/2. for ss in shape]
    y,x = np.ogrid[-m:m+1,-n:n+1]
    h = np.exp( -(x*x + y*y) / (2.*sigma*sigma) )
    h[ h < np.finfo(h.dtype).eps*h.max() ] = 0
    sumh = h.sum()
    if sumh != 0:
        h /= sumh
    return h</code></pre>
		
		<p>Even though our matrices don't match perfectly with the SExtractor output (component by component), they are close and a direct question to E. Bertin could help us in improving the calculation of the matrices.  </p>
		
		
		<li><b>Detection + Deblending:</b></li>
		
		<p>SExtractor uses thresholding for detecting objects that satisfy the following requirements:</p>
		
		<ul>
			<li>All the pixels are above a certain value called DETECT_THRESH (in our case, it was set up as 1.5 sigmas above the mean background value).</li>
			<li>All these pixels are adjacent to each other.</li>
			<li>There are more than the minimum a number of pixels, specified with the value of DETECT_MINAREA, which in our case is 5 pixels.</li>
		</ul>
		
		<p>An important task that SExtractor does is what we call deblending; it means SE decides whether or not a group of adjacent pixels above the threshold is a single object or not, depending on the value of DEBLEND_NTRESH, which is a very sensitive parameter and we didn't 'toy' with it enough.</p>
		
		<li><b>Photometry:</b></li>
		<p>We didn't pick up a unique way of measuring the flux (ISO, ISOCORR, BEST, AUTO), with the additional value of photometric zeropoint for calibrating the magnitudes (even though at the end we 'skipped' the extinction and color term); it's up to Team 3 choosing the best one.</p>
		
		
	</ol>
	
	<p>Future possible improvements:</p>
	<ul>
		<li>Play with more values for thresholding and deblending and test them for improving the detection of faint and nearby objects, respectively.</li>
		<li>Gaussian filters: we need to quantify the power of this tool and eventually 'create' the best PSF model for our images (replace the code of MATLAB).</li>
		<li>Contacting E. Bertin for details in the calculation of magnitudes and gaussian filters.</li>
		<li>Using a full calibration for the magnitudes (even if in our case we are going to 'add' some constants).</li>

	</ul>
	
	<p></p>
	<h4> Cross-Reference with Virtual Observatory Catalogs  </h2>
    <p>
STILTS (Starlink Tables Infrastructure Library Tool Set) is a command line interface toolkit that uses the same underlying engine as the graphical user interface program TOPCAT.  Using STILTS, we cross-reference our catalogs extracted from images with Virtual Observatory’s online catalog.   As STILTS accepts catalogs in VOTable format, we configured SExtractor to output catalogs in VOTables.  Online catalogs, such as 2MASS, then were queried to return additional information, such as measurements of different color filters, about the objects in the catalog.  The retrieved information is intended to help classify astronomical objects in addition to the fields extracted by SExtractor.
    </p>
	
	<h4> HPC </h4>
	<p>The NLHPC is in place to provide a computing capacity in Chile meeting the national scientific demand for high performance computing (HPC).</p>
	<p>The Leftraru cluster consists of 128 Nodes HP SL230 and four HP SL250, with 2640 cores Intel Ivy Bridge E5-2660V2, 12 Xeon Phi 5110p, and 5.4 TB of RAM, and a 56GB FDR connection with an available 274TB of storage.</p>
	<p>The pipeline constructed by the group executes over 20.000 tasks, one per image, in which the images go through the process of cosmic ray removal (with the customized crblaster), then identification of objects, and extraction of the features and  generation of the output catalogs (with the adjusted SExtractor), and finally addition of the virtual observatory catalogs (generated with stilts).</p>
	<p>The code for Leftraru was writen in slurm, and runs using a master python script that calls the individual subscripts which contain the sub processes for the tasks. The slurm code starts with a list of avialble image paths and proceeds to process each image in parallel. </p>
	
        </div>  
	</div>    
	<div class="footer">
        <p><b>Group 1:</b> Lyla Fadden, Ismael Alvarez, Minjae Kim, Diego Farías</p>
      </div>

    </div> <!-- /container -->


    <!-- Bootstrap core JavaScript
    ================================================== -->
    <!-- Placed at the end of the document so the pages load faster -->
    <!-- jQuery (necessary for Bootstrap's JavaScript plugins) -->
    <script src="https://code.jquery.com/jquery.js"></script>
    <!-- Include all compiled plugins (below), or include individual files as needed -->
    <script src="//netdna.bootstrapcdn.com/bootstrap/3.0.2/js/bootstrap.min.js"></script>
  </body>
</html>
