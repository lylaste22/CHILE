<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="">
    <meta name="author" content="">
    <!-- <link rel="shortcut icon" href="../../docs-assets/ico/favicon.png"> -->

    <title>CHILE 2015</title>

    <!-- Bootstrap core CSS -->
    <link href="//netdna.bootstrapcdn.com/bootswatch/3.0.2/yeti/bootstrap.min.css" rel="stylesheet">

    <!-- Custom styles for this template -->
    <link href="http://getbootstrap.com/examples/jumbotron-narrow/jumbotron-narrow.css" rel="stylesheet">

    <!-- Just for debugging purposes. Don't actually copy this line! -->
    <!--[if lt IE 9]><script src="../../docs-assets/js/ie8-responsive-file-warning.js"></script><![endif]-->

    <!-- HTML5 shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!--[if lt IE 9]>
      <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
      <script src="https://oss.maxcdn.com/libs/respond.js/1.3.0/respond.min.js"></script>
    <![endif]-->
    <script type="text/javascript" src="http://latex.codecogs.com/latexit.js"></script>
	<style>
table, th, td {
   padding: 20px;
}
</style>
  </head>

  <body>

    <div class="container">
      <div class="header">
        <ul class="nav nav-pills pull-right">
          <li><a href="index.html">Home</a></li>
          <li><a href="group1.html">Group 1</a></li>
          <li class="active"><a href="group2.html">Group 2</a></li>
          <li><a href="group3.html">Group 3</a></li>
          <li><a href="https://github.com/lylaste22/CHILE" target="_blank">Code</a></li>
        </ul>
        <h3 class="text-muted">CHILE 2015</h3>
      </div>

      <div class="container">
        <h1 style="text-align:center">Chile-Harvard Innovative Learning Exchange 2015</h1>
      </div>
	<div class="jumbotron">
          <iframe src="//player.vimeo.com/video/85621568?color=ffffff" width="520" height="293" frameborder="0" webkitallowfullscreen mozallowfullscreen allowfullscreen></iframe>
      </div>


      <div class="row marketing">
        <div class="col-md-12">
	
	<h3>Task Description</h3>
	<p>The objective of our work was to develop a classifier of different types of astronomical objects present in the Dark Energy Survey (DES) data.  We possess a catalog –developed by <i>Group 1</i>– with all the astronomical objects and information on their relevant (about 25) features; including their celestial position, apparent magnitude and ellipticity. Moreover, as each DES field has been observed about 20 times (4 times a night for 5 consecutive days), we have time as an additional dimension of the dataset.  Given the characteristics of the data, our main goal was being able to discriminate between stars, galaxies, asteroids and artifacts.</p>
        
        <p>For this purpose, we first distinguished between moving and non-moving objects using DBSCAN, a clustering algorithm, by stacking all the epochs onto one plane and searching for clusters.  Then, we classified non-moving objects as stars, galaxies or artifacts using a machine learning approach.  Finally, within our moving objects set, we searched for asteroids by first implementing a modified version of the Hough transform to link sources between epochs and then using DBSCAN to establish if they could possibly be the same object or not. This way, we were able to identify real astronomical objects that were present in different epochs, but that changed their position in time, as a same source.</p>

        <center>
          <img class="" src="images/group2_flowchart.png" width="70%" height="70%"/>
        </center>
        
        <h3>Moving / Non-Moving Object Classification</h3>
        <p>To do the classification between moving and non-moving objects, we ran the DBSCAN clustering algorithm on a dataset that included the 20 epochs of detections.  DBSCAN is a density-based clustering algorithm which places in the same cluster two elements if they have a distance that is less than a specific threshold, and it doesn't need the number of clusters as a parameter. Thus, by stacking all 20 epochs onto one plane, each cluster represented a non-moving astronomical object, while non-clustered objects represented a moving object that could either be an asteroid or an artifact present on the original images. We established 0.003 degrees (about 1.08 arcseconds) as the distance threshold parameter for DBSCAN, and only considered clusters that were constituted by at least 3 members.</p>
        
        <p>An example of running DBSCAN in a subset of the data can be seen below, where the x-axis stands for right ascension and the y-axis for declination –both in degrees–.  Colored dots represent non-moving objects (the zoomed-in area shows that they are in fact clusterized dots), while gray dots represent moving objects.</p>

        <center>
          <img class="" src="images/dbscan_plot.png" width="85%" height="85%"/>
        </center>
       
        
        <h3>Star / Galaxy Classification</h3>
        <p>To be able to distinguish between stars and galaxies as efficiently as possible, we first start by considering a particular feature that Source Extractor assigns to each of its detections.  This parameter, <i>CLASS_STAR</i>, represents how confident SExtractor is in classifying each object as a star based on its own Neural Network algorithm.  <i>CLASS_STAR</i> can take a value between 0 and 1, where 0 correponds to galaxy (or, more precisely, non-star) and 1 corresponds to star.  Thus, we assumed we could label –with relatively high confidence– as <b>'star'</b> every object with a <i>CLASS_STAR</i> value greater than 0.9, and label as a <b>'galaxy'</b> the objects with a value smaller than 0.1.  For each non-moving object cluster, we considered the median value of its constituting members.  If the median <i>CLASS_STAR</i> value of an object fell between 0.1 and 0.9, we labeled them as <b>'undetermined'</b>.</p>
        <p>As the next step, we used supervised learning to reclassify the undetermined objects as either stars or galaxies, basing ourselves on our labeled set and the additional 24 features provided by SExtractor.  To test the quality of this approach, we split our labeled dataset in two: a random 50% of it was assigned to be the training set, while the remaining 50% was appointed to the testing set.  We obtained around 95% accuracy during several repetitions of this experiment, which we consider to be satisfactory.</p>
        
        <p>To do the classification, we first reduced the dimensionality of the dataset from 24 to 10 features using Principal Component Analysis (PCA) to recover the most relevant information.  Afterwards, we classified the data through two different approaches: Random Forests and Linear Discriminant Analysis (LDA).  All the objects which ended up having coinciding labels (either 'star' <i>or</i> 'galaxy') after passing through both of the classifiers were finally taken into account and saved, while objects with non-coinciding labels were discarded (thus, these stayed as 'undetermined').  As part of our role as <i>Group 2</i> in the overall work-flow, we provide a catalog of all the objects we classified as stars to <i>Group 3</i>.</p>
        
        <p>We would like to note that we intended to include active learning in our classification method, but did not have enough time to implement it.  The idea consists in that the output labels (star/galaxy/undetermined) of each object could have been re-evaluated based on visual inspection of the source ("<i>does it actually look like a star –or galaxy–?</i>") combined with cross-checking certain key parameters (e.g., if the object is labeled as a star, "<i>does the image's expected full-width at half-maximum (FWHM) of a star-like object coincide with the gaussian FWHM that SExtractor calculated?</i>"). Thus, a human-relabeled sample would have been given back to our classifers, which we assume would have improved their accuracy if we iterated this process.</p>
	
	
	<h3>Asteroid Identification</h3>
	<p>Once we already had a dataset of moving-objects, we had to determine when sources of different epochs corresponded to the same astronomical object. To do that, we worked with the asumption that we could aproximate the trajectory of every asteroid to a straight line, and then, search for colinearity between sources. We considered all the lines between pairs of detections using a modified version of Hough Transformation in three dimensions, using the following ecuations:</p>
	<center>
	<table>
	<tr>
	<td>
	<div lang="latex">
	\theta = arctan\left(\frac{y_1 - y_2}{x_1 - x_2}\right)
	</div>
	</td>
	<td>
	<div lang="latex">
	x_0 = arctan\left(\frac{x_1 t_2+x_2 t_1}{t_1 - t_2}\right)
	</div>
	</td>
	</tr>
	<tr>
	<td>
	<div lang="latex">
	y_0 = arctan\left(\frac{y_1 t_2+t_2 t_1}{t_1 - t_2}\right)
	</div>
	</td>
	<td>
	<div lang="latex">
	\nu = arctan\left(\frac{y_1 - y_2}{x_1 - x_2}\right)
	</div>
	</td>
	</tr>
	</table>
	</center>

        
	
<p>After doing this parametrization, we runned DBSCAN on top of a dataset of four dimensions in which each point represented a straight line which passes through two observation points. In our new space, high density spots would represent places where there are many straight lines coinciding, therefore we would find colinearity between several point in the original space. </p>
<center>
<img id="#i1" src="images/super_asteroide.png" width="60%" height="60%"/>
<img id="#i2" src="images/movie.gif" width="100%" height="100%"/>

        </center>
<p>The animation above corresponds to snapshots of an asteroid on sequential epochs.  In particular, this moving-object is the one represented on the left of the plot, and as it can be appreciated it was observed in all the five consecutive days of observations with DECam.  On five days of observations, this asteroid was imaged on the same CCD of the same field, and we can confirm it is a very slow-moving object with a speed of about 3.34 arcseconds/hour.  Given its characteristics, it is most probable that this asteroid corresponds to a Trans-Neptunian Object (TNO): an object that lies beyond Neptune, the farthest planet from the Sun in the Solar System, and thus could lie more than 30 AUs away.</p>
   </div>  
</div> 
<div class="footer"><b>Group 2:</b> Pablo Huentelemu, Josefina Michea, Lucas Valenzuela, Xufei Wang  </p>
      </div>

    </div> <!-- /container -->


    <!-- Bootstrap core JavaScript
    ================================================== -->
    <!-- Placed at the end of the document so the pages load faster -->
    <!-- jQuery (necessary for Bootstrap's JavaScript plugins) -->
    <script src="https://code.jquery.com/jquery.js"></script>
    <!-- Include all compiled plugins (below), or include individual files as needed -->
    <script src="//netdna.bootstrapcdn.com/bootstrap/3.0.2/js/bootstrap.min.js"></script>
  </body>
</html>
